workflow:
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "web"

stages:
  - unit tests
  - generate
  - build base containers
  - build cache
  - build spacktainer containers
  - cleanup

variables:
  SPACK_BRANCH: develop

generate base pipeline:
  image: ubuntu:latest
  stage: generate
  needs: []
  variables:
    SINGULARITY_VERSION: 4.0.2
    S3CMD_VERSION: 2.3.0
  script:
    - apt-get update && apt-get install -y ca-certificates git podman python3 python3-pip skopeo
    - pip install --upgrade pip setuptools
    - pip install -e ./job_creator
    - jc create-jobs --singularity-version ${SINGULARITY_VERSION} --s3cmd-version ${S3CMD_VERSION}
  artifacts:
    when: always
    paths:
      - generated_pipeline.yaml
      - spacktainer.yaml
      - merged_spack*yaml
      - job_creator.log
      - spacktainer
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "web"

base containers and pipeline generation:
  stage: build base containers
  needs:
    - job: generate base pipeline
      artifacts: true
  trigger:
    include:
      - artifact: generated_pipeline.yaml
        job: generate base pipeline
    strategy: depend
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "web"

gather child artifacts:
  stage: build cache
  needs: [base containers and pipeline generation]
  image: ubuntu:latest
  script:
    - apt-get update && apt-get install -y ca-certificates git python3 python3-pip unzip
    - pip install --upgrade pip setuptools
    - pip install -e ./get_artifacts
    - ga -P ${CI_PIPELINE_ID} -t ${GITLAB_API_TOKEN}
    - for zipfile in $(ls spack.artifacts*zip); do
    -    unzip ${zipfile} -d ${zipfile%%.zip}
    -    rm -f ${zipfile}
    -    architecture=$(echo ${zipfile##spack.artifacts.} | sed 's/.zip//')
    -    echo ${architecture}=yes >> build.env
    - done
    - for zipfile in $(ls spacktainer.artifacts*zip); do
    -    unzip ${zipfile} -d ${zipfile%%.zip}
    -    rm -f ${zipfile}
    - done
    - cat build.env
  artifacts:
    when: always
    paths:
      - spack.artifacts.*
      - spacktainer.artifacts.*
    reports:
      dotenv: build.env
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "web"

populate buildcache for amd64:
  stage: build cache
  needs:
    - job: gather child artifacts
      artifacts: true
  trigger:
    include:
      - artifact: spack.artifacts.amd64/spack_pipeline.yaml
        job: gather child artifacts
    strategy: depend
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "web"

populate buildcache for arm64:
  stage: build cache
  needs:
    - job: gather child artifacts
      artifacts: true
  trigger:
    include:
      - artifact: spack.artifacts.arm64/spack_pipeline.yaml
        job: gather child artifacts
    strategy: depend
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "web"


build spacktainers for amd64:
  stage: build spacktainer containers
  needs:
    - job: gather child artifacts
      artifacts: true
    - populate buildcache for amd64
  trigger:
    include:
      - artifact: spacktainer.artifacts.amd64/artifacts.amd64/spacktainer_pipeline.yaml
        job: gather child artifacts
    strategy: depend
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "web"

build spacktainers for arm64:
  stage: build spacktainer containers
  needs:
    - job: gather child artifacts
      artifacts: true
    - populate buildcache for arm64
  trigger:
    include:
      - artifact: spacktainer.artifacts.arm64/artifacts.arm64/spacktainer_pipeline.yaml
        job: gather child artifacts
    strategy: depend
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_PIPELINE_SOURCE == "web"

test spackitor:
  stage: unit tests
  image: python:3.10-buster
  script:
    - pip install './spackitor[test]'
    - coverage run -m pytest --junit-xml=unittests.xml -vs spackitor/tests
    - coverage report
    - coverage xml
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      changes:
        - spackitor/**/*
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    when: always
    reports:
      junit: unittests.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml


cleanup deleted branch containers from the bucket:
  stage: cleanup
  image: bbpgitlab.epfl.ch:5050/hpc/spacktainerizah/singularitah:latest
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: never
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "web"
  before_script:
    - sed -i 's/^access_key.*/access_key='${AWS_INFRASTRUCTURE_ACCESS_KEY_ID}'/' /root/.s3cfg
    - sed -i 's/^secret_key.*/secret_key='${AWS_INFRASTRUCTURE_SECRET_ACCESS_KEY}'/' /root/.s3cfg
    - let length=$(($(echo $(expr index ${HTTP_PROXY:7} :)) - 1))
    - PROXY_HOST=${HTTP_PROXY:7:${length}}
    - PROXY_PORT=${HTTP_PROXY:$((7+${length}+1))}
    - sed -i 's/^proxy_host.*/proxy_host='${PROXY_HOST}'/' /root/.s3cfg
    - sed -i 's/^proxy_port.*/proxy_port='${PROXY_PORT}'/' /root/.s3cfg
    - cat /root/.s3cfg
  script:
    - git fetch
    - git branch -r | sed 's|origin/||'
    - branches=($(git branch -r | sed 's|origin/||' | awk '{print $NF}'))
    - echo "Existing branches are ${branches[*]}"
    - for container in $(s3cmd ls s3://sboinfrastructureassets/containers/spacktainerizah/ | awk '{print $4}'); do
    -     container_branch=$(echo $container | awk -F'__' '{print $3}')
    -     if [[ -z "${container_branch}" ]] || [[ ${container_branch} == *.sif ]] ; then
    -         echo "no branch for ${container} - skipping"
    -     fi
    -     echo "Container ${container} was built with branch ${container_branch}"
    -     if [[ ! " ${branches[*]} " =~ " ${container_branch} " ]]; then
    -         echo "${container_branch} not found in existing branches"
    -         s3cmd rm ${container}
    -     else
    -         echo "The branch still exists, it can stay"
    -     fi
    - done

cleanup deleted branch containers from bb5:
  stage: cleanup
  tags: [bb5_map]
  variables:
    CONTAINER_ROOT: /gpfs/bbp.cscs.ch/ssd/containers/hpc/spacktainerizah
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: never
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "web"
  script:
    - module load unstable git
    - git fetch
    - git branch -r | sed 's|origin/||'
    - branches=($(git branch -r | sed 's|origin/||' | awk '{print $NF}'))
    - echo "Existing branches are ${branches[*]}"
    - for container in $(ls ${CONTAINER_ROOT}); do
    -     container_branch=$(echo $container | awk -F'__' '{print $3}')
    -     if [[ -z "${container_branch}" ]] || [[ ${container_branch} == *.sif ]] ; then
    -         echo "no branch for ${container} - skipping"
    -     fi
    -     echo "Container ${container} was built with branch ${container_branch}"
    -     if [[ ! " ${branches[*]} " =~ " ${container_branch} " ]]; then
    -         echo "${container_branch} not found in existing branches"
    -         rm -f ${CONTAINER_ROOT}/${container}.sif
    -     else
    -         echo "The branch still exists, it can stay"
    -     fi
    - done
